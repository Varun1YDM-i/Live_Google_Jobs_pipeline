{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21810373-de23-465b-b473-14e0d737c679",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import requests,json \n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e1a3a19-e5a0-4ad0-8e4c-f890c6606fd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defining the Spark Session named Google_JobETL_Bronze\n",
    "app_name = \"Google_JobETL_Bronze\"\n",
    "spark = SparkSession.builder.appName(app_name).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fafbeed-4d05-4a3a-ad1c-37032bb77211",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# checking spark Session name (appname)\n",
    "print('App Name :',app_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a372d715-b55b-4b3a-a806-3180cce8773b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Checking all the catalogs in unity-catalog\n",
    "display(spark.sql('SHOW CATALOGS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d74ffeef-224b-460d-838d-741348a09fef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display( spark.sql('SHOW SCHEMAS') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88967e4c-8b99-4321-8bd1-aa7ab4bb51ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Checking the current unity-catalog and creating catalog if not present and using it\n",
    "spark.sql(' CREATE CATALOG IF NOT EXISTS job_marketplace ')\n",
    "spark.sql(' USE CATALOG job_marketplace ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c503ce8-6f3f-487c-852e-01af3f41fd97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# displaying default present schemas in the job_marketplace catalog\n",
    "display( spark.sql('SHOW SCHEMAS') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4891199-d216-4193-a259-458db1147c03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# checking and creating the bronze_layer schema in the job_marketplace catalog\n",
    "spark.sql('CREATE SCHEMA IF NOT EXISTS job_marketplace.bronze_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a613d84f-d510-4fd1-9cdc-56bb56533bfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Checking if the bronze layer schema is present in the job_marketplace catalog\n",
    "display( spark.sql('SHOW SCHEMAS') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c2d8aba-3133-4839-8c5b-86d15995a1b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display( spark.sql('SHOW TABLES') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75debfa8-2725-4554-b923-dce9ea3ce62e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- table for securing api key\n",
    "CREATE TABLE IF NOT EXISTS secure_config (\n",
    "  key STRING,\n",
    "  value STRING\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84af0e4a-3519-4463-8172-0febdbcc5088",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# defining the API key\n",
    "api_key = (\n",
    "    spark.table(\"secure_config\")\n",
    "    .filter(\"key = 'openai_api'\")\n",
    "    .select(\"value\")\n",
    "    .first()[0]\n",
    ")\n",
    "# Defining the roles and location parameters to get from the google jobs API\n",
    "roles = [\"Data Engineer\", \"Python Developer\", \"ETL Developer\", \"Spark Engineer\", \"Data Analyst\"]\n",
    "location = \"India\"\n",
    "# Defining the all_jobs lists to store all the jobs search results from the Google Jobs API\n",
    "all_jobs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c31eea61-d808-4135-bc50-a1a8b9bf691b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Running loop over all the job roles\n",
    "for role in roles:\n",
    "    params={\n",
    "        \"engine\":\"google_jobs\",\n",
    "        \"q\":role,\n",
    "        \"location\":location,\n",
    "        \"api_key\":api_key\n",
    "    }\n",
    "    # making a request to the google jobs API for each job\n",
    "    res = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
    "    print(f\"âœ…Reading ðŸ”´LIVE Data from Google Jobs API for {role} role\")\n",
    "    # storing the jobs search results in the all_jobs list\n",
    "    jobs = res.json().get(\"jobs_results\", [])\n",
    "    # appending the searched_role name to each job\n",
    "    for job in jobs:\n",
    "        job[\"search_role\"] = role\n",
    "    print(f\"Appended {role} role Data to all_jobs list\")\n",
    "    all_jobs.extend(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "017ad689-db8a-4e61-b5e7-3dca6490a20f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# checking the all_jobs list with the all the jobs\n",
    "print(all_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7088f4a4-d032-460c-8e05-14dbbd70097f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Writing the data to the bronze layer tables\n",
    "bronze_df = spark.createDataFrame(all_jobs)\n",
    "\n",
    "bronze_df.write.format(\"delta\")\\\n",
    "                .option(\"mergeSchema\", \"true\")\\\n",
    "                .mode(\"overwrite\")\\\n",
    "                .saveAsTable(\"job_marketplace.bronze_layer.daily_jobs\")\n",
    "\n",
    "bronze_df.write.format(\"delta\")\\\n",
    "                .option(\"mergeSchema\", \"true\")\\\n",
    "                .mode(\"append\")\\\n",
    "                .saveAsTable(\"job_marketplace.bronze_layer.raw_jobs\")\n",
    "\n",
    "print(\"âœ…Data Written to Bronze Layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7503f7f-9c38-4b24-8727-1fbf499ea35d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- checking if the data loaded to the bronze table\n",
    "select * from job_marketplace.bronze_layer.raw_jobs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "721ab456-18ec-4e64-af55-f106801d331f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from job_marketplace.bronze_layer.daily_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2536dc71-f915-46a4-bd30-f36631d0696c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "select * from job_marketplace.bronze_layer.raw_jobs limit 1;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [
    {
     "elements": [],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "00f3df28-844f-4729-bc01-40bf754e62eb",
     "origId": 7117076767305862,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4937880514231175,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze_Layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
